{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from scipy.io import wavfile\n",
    "import librosa.display\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:/Competition/ETRI Competition/RAW DATA/KEMDy19/wav/train/Session01/Sess01_impro01/Sess01_impro01_F001.wav',\n",
       " 'E:/Competition/ETRI Competition/RAW DATA/KEMDy19/wav/train/Session01/Sess01_impro01/Sess01_impro01_F002.wav',\n",
       " 'E:/Competition/ETRI Competition/RAW DATA/KEMDy19/wav/train/Session01/Sess01_impro01/Sess01_impro01_F003.wav']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'E:/Competition/ETRI Competition/RAW DATA/KEMDy19/wav/train'    #데이터폴더 경로 지정해주기 \n",
    "parent_folders = os.listdir(path)                     #폴더 불러오기\n",
    "path_li = []\n",
    "total_sum = 0\n",
    "for parent_folder in parent_folders:\n",
    "    child_folders = []\n",
    "    child_folders.append((np.array(os.listdir(path+\"/\"+parent_folder)).flatten().tolist())) # wav에 있는 폴더 다 불러오기\n",
    "    temp_folders = (np.array(child_folders)).flatten().tolist()\n",
    "    for folder in temp_folders:\n",
    "        files = os.listdir(path+\"/\"+parent_folder+\"/\"+folder) #sessio01폴더 불러오기\n",
    "        for file in files:\n",
    "            if (path+\"/\"+parent_folder+'/'+folder+'/'+file).endswith('.wav') == True: # session01_impro01안에있는 txt 파일만 순서대로 path_li로 보내기\n",
    "                path_li.append(path+\"/\"+parent_folder+\"/\"+folder+\"/\"+file)\n",
    "\n",
    "path_li[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9360\n"
     ]
    }
   ],
   "source": [
    "print(len(path_li))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14-45초 음성 파일을 10초자리로 sliding_window 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14초~45초 되는 음성 파일들을 가져옴\n",
    "audio_files = []\n",
    "for filename in path_li: # 음성 파일이 저장된 폴더 경로\n",
    "    y, sr = librosa.load(filename, sr=16000)\n",
    "    duration = librosa.get_duration(y=y, sr=sr)\n",
    "    if duration < 14 or duration >= 45:\n",
    "        continue\n",
    "    audio_files.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(audio_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sliding window 크기 (10초)\n",
    "window_size = 10\n",
    "\n",
    "# sliding window 간격 (10초)\n",
    "hop_size = 5\n",
    "\n",
    "# 14초~45초 되는 음성 파일들을 저장할 폴더 경로\n",
    "sliding_window = 'E:/Competition/ETRI Competition/RAW DATA/KEMDy19/wav/train/sliding window'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sliding window을 적용하여 데이터 쪼개기\n",
    "for file_path in audio_files:\n",
    "    filename = os.path.basename(file_path)\n",
    "    y, sr = librosa.load(file_path, sr=16000, offset=0)\n",
    "    for i in range(0, len(y) - window_size * sr + hop_size * sr, hop_size * sr):\n",
    "        if i + window_size * sr > len(y):\n",
    "            window = y[-window_size * sr:]\n",
    "        else:\n",
    "            window = y[i:i + window_size * sr]\n",
    "        output_file = os.path.join(sliding_window, f'{filename}_{i+window_size}s.wav')\n",
    "        sf.write(output_file, window, sr, subtype='PCM_16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_delete in audio_files:  #14초이상 45초 미만 음성파일 삭제\n",
    "    os.remove(file_delete)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 음성 mfcc 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\librosa\\feature\\spectral.py:2157: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-569.62384  , -543.4611   , -564.1664   , ...,    0.       ,\n",
       "           0.       ,    0.       ],\n",
       "       [  84.5566   ,   79.78537  ,   89.013435 , ...,    0.       ,\n",
       "           0.       ,    0.       ],\n",
       "       [   3.384592 ,  -11.527005 ,  -15.091857 , ...,    0.       ,\n",
       "           0.       ,    0.       ],\n",
       "       ...,\n",
       "       [   1.2283611,    1.2559738,    3.4666843, ...,    0.       ,\n",
       "           0.       ,    0.       ],\n",
       "       [  -5.042471 ,   -5.5685244,   -4.6630964, ...,    0.       ,\n",
       "           0.       ,    0.       ],\n",
       "       [  -3.0495148,   -1.4369392,   -4.6570053, ...,    0.       ,\n",
       "           0.       ,    0.       ]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 음성 파일을 feaher로 생성\n",
    "\n",
    "max_pad_len = 3300\n",
    "hop_length = 160  # 전체 frame 수 (hop_length의 길이만큼 옆으로 가면서 데이터를 읽는 옵션, 10ms를 기본으로 하고 있어 16000Hz인 음성에서는 160에 해당)\n",
    "n_fft = 400       # frame 하나당 sample 수(일반적으로 자연어 처리에서는 음성을 25m의 크기를 기본으로 하고 있으며 16000Hz인 음성에서는 400에 해당하는 값) \n",
    "\n",
    "out = []\n",
    "for file in path_li:\n",
    "    data, sr = librosa.load(file)  # librosa로 음성 데이터 불러오기\n",
    "    mfccs = librosa.feature.mfcc(y=data, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mfcc=128)  #mfcc로 음성을 array형태로 나타냄\n",
    "    # print(mfccs)\n",
    "    pad_width = max_pad_len - mfccs.shape[1]  # shape 만들기\n",
    "    if pad_width > 0:\n",
    "        mfcc_sh = np.pad(mfccs, pad_width=((0,0), (0, pad_width)), mode='constant')\n",
    "        out.append(mfcc_sh)\n",
    "    else:\n",
    "        out.append(mfccs[:,:max_pad_len])\n",
    "    # print(mfcc_sh.shape)    \n",
    "out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9360"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Segment ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sess01_impro01_F001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sess01_impro01_F002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sess01_impro01_F003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sess01_impro01_F004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sess01_impro01_F005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9355</th>\n",
       "      <td>Sess20_script05_M013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9356</th>\n",
       "      <td>Sess20_script05_M013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9357</th>\n",
       "      <td>Sess20_script06_M022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9358</th>\n",
       "      <td>Sess20_script06_M022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9359</th>\n",
       "      <td>Sess20_script06_M022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9360 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Segment ID\n",
       "0      Sess01_impro01_F001\n",
       "1      Sess01_impro01_F002\n",
       "2      Sess01_impro01_F003\n",
       "3      Sess01_impro01_F004\n",
       "4      Sess01_impro01_F005\n",
       "...                    ...\n",
       "9355  Sess20_script05_M013\n",
       "9356  Sess20_script05_M013\n",
       "9357  Sess20_script06_M022\n",
       "9358  Sess20_script06_M022\n",
       "9359  Sess20_script06_M022\n",
       "\n",
       "[9360 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seesid_li = []\n",
    "label_li = []\n",
    "for path in path_li:\n",
    "    seesid = (path.split('/')[-1].split('.')[0])\n",
    "    seesid_li.append(seesid)\n",
    "seesid_df = pd.DataFrame(seesid_li)\n",
    "seesid_df.columns = ['Segment ID']\n",
    "seesid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = 'E:/Competition/ETRI Competition//Analysis/감정 레이블/train 감정_보이스'     # 감정레이블 경로설정\n",
    "label_filename = os.listdir(label_path)                                                  # 경로 설정한 폴더 열기\n",
    "label_li = [label_file for label_file in label_filename if label_file.endswith('.csv')]  # .csv 파일만 블러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8187\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Numb</th>\n",
       "      <th>Segment ID</th>\n",
       "      <th>Total Evaluation Emotion</th>\n",
       "      <th>Total Evaluation Valence</th>\n",
       "      <th>Total Evaluation Arousal</th>\n",
       "      <th>Eval01F Emotion</th>\n",
       "      <th>Eval01F Valence</th>\n",
       "      <th>Eval01F Arousal</th>\n",
       "      <th>Eval02F Emotion</th>\n",
       "      <th>Eval02F Valence</th>\n",
       "      <th>...</th>\n",
       "      <th>Eval15M Arousal</th>\n",
       "      <th>Eval16M Emotion</th>\n",
       "      <th>Eval16M Valence</th>\n",
       "      <th>Eval16M Arousal</th>\n",
       "      <th>Eval17M Emotion</th>\n",
       "      <th>Eval17M Valence</th>\n",
       "      <th>Eval17M Arousal</th>\n",
       "      <th>Eval19M Emotion</th>\n",
       "      <th>Eval19M Valence</th>\n",
       "      <th>Eval19M Arousal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Sess01_script01_M001</td>\n",
       "      <td>surprise</td>\n",
       "      <td>1.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>surprise</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>surprise</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sess01_script01_F001</td>\n",
       "      <td>fear</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>fear</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>fear</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Sess01_script01_M002</td>\n",
       "      <td>angry</td>\n",
       "      <td>1.3</td>\n",
       "      <td>4.3</td>\n",
       "      <td>angry</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>angry</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Sess01_script01_M003</td>\n",
       "      <td>angry</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>angry</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>surprise</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Sess01_script01_F002</td>\n",
       "      <td>fear</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>fear</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>fear</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Numb            Segment ID Total Evaluation Emotion  \\\n",
       "0     1  Sess01_script01_M001                 surprise   \n",
       "1     2  Sess01_script01_F001                     fear   \n",
       "2     3  Sess01_script01_M002                    angry   \n",
       "3     4  Sess01_script01_M003                    angry   \n",
       "4     5  Sess01_script01_F002                     fear   \n",
       "\n",
       "   Total Evaluation Valence  Total Evaluation Arousal Eval01F Emotion  \\\n",
       "0                       1.7                       4.0        surprise   \n",
       "1                       1.5                       3.6            fear   \n",
       "2                       1.3                       4.3           angry   \n",
       "3                       1.5                       3.8           angry   \n",
       "4                       1.6                       3.7            fear   \n",
       "\n",
       "   Eval01F Valence  Eval01F Arousal Eval02F Emotion  Eval02F Valence  ...  \\\n",
       "0              2.0              5.0        surprise              2.0  ...   \n",
       "1              2.0              4.0            fear              1.0  ...   \n",
       "2              1.0              5.0           angry              2.0  ...   \n",
       "3              2.0              4.0        surprise              2.0  ...   \n",
       "4              3.0              4.0            fear              1.0  ...   \n",
       "\n",
       "   Eval15M Arousal Eval16M Emotion  Eval16M Valence  Eval16M Arousal  \\\n",
       "0              NaN             NaN              NaN              NaN   \n",
       "1              NaN             NaN              NaN              NaN   \n",
       "2              NaN             NaN              NaN              NaN   \n",
       "3              NaN             NaN              NaN              NaN   \n",
       "4              NaN             NaN              NaN              NaN   \n",
       "\n",
       "  Eval17M Emotion  Eval17M Valence  Eval17M Arousal Eval19M Emotion  \\\n",
       "0             NaN              NaN              NaN             NaN   \n",
       "1             NaN              NaN              NaN             NaN   \n",
       "2             NaN              NaN              NaN             NaN   \n",
       "3             NaN              NaN              NaN             NaN   \n",
       "4             NaN              NaN              NaN             NaN   \n",
       "\n",
       "   Eval19M Valence  Eval19M Arousal  \n",
       "0              NaN              NaN  \n",
       "1              NaN              NaN  \n",
       "2              NaN              NaN  \n",
       "3              NaN              NaN  \n",
       "4              NaN              NaN  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 감정라벨\n",
    "total_label_df = pd.DataFrame()  \n",
    "for filename in label_li:\n",
    "    temp_label_df = pd.read_csv(label_path+'/'+filename)  # 감정레이블 파일 내용 읽어드리기\n",
    "    total_label_df = pd.concat([total_label_df, temp_label_df], axis=0) \n",
    "\n",
    "total_label_df = total_label_df.reset_index(drop=True) \n",
    "print(len(total_label_df))\n",
    "\n",
    "total_label_df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wav 파일 기준으로 음성파일과 segment id가 동일하다면 Total Evaluation Emotion값을 가져옴\n",
    "label_value_li = []\n",
    "for i in range(len(seesid_df)):\n",
    "   for k in range(len(total_label_df)):\n",
    "           if seesid_df['Segment ID'][i] == total_label_df['Segment ID'][k]:\n",
    "               label_value_li.append(total_label_df.loc[k, 'Total Evaluation Emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label=pd.DataFrame(label_value_li)\n",
    "train_label\n",
    "train_label.to_csv(\"final_train_label0854.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9355</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9356</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9357</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9358</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9359</th>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9360 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0     neutral\n",
       "1     neutral\n",
       "2     neutral\n",
       "3     neutral\n",
       "4     disgust\n",
       "...       ...\n",
       "9355  neutral\n",
       "9356  neutral\n",
       "9357    angry\n",
       "9358    angry\n",
       "9359    angry\n",
       "\n",
       "[9360 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label= pd.read_csv('E:/Competition/ETRI Competition/Analysis/final_train_label0854.csv')\n",
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9360"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_value_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9360, 128, 3300)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.array(out)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9360, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(train_label)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9360, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = to_categorical(le.fit_transform(y))\n",
    "y_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_columns = 3300    \n",
    "n_row = 128       \n",
    "n_channels = 1\n",
    "n_classes = 7\n",
    "\n",
    "# input shape 조정\n",
    "x_train_input = tf.reshape(x_train, [-1, n_row, n_columns, n_channels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 126, 3298, 64)     640       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 63, 1649, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 63, 1649, 64)      0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 62, 1648, 128)     32896     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 31, 824, 128)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 31, 824, 128)      0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 30, 823, 128)      65664     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 15, 411, 128)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 15, 411, 128)      0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 410, 256)      131328    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 7, 205, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 7, 205, 256)       0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 7)                 1799      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 232,327\n",
      "Trainable params: 232,327\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(input_shape=(n_row, n_columns, n_channels), filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=2))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Conv2D(kernel_size=2, filters=128, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=2))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Conv2D(kernel_size=2, filters=128, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=2))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Conv2D(kernel_size=2, filters=256, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=2))\n",
    "model.add(layers.Dropout(0.1))\n",
    "\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(tf.keras.layers.Dense(units=7, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=10)  # val_loss값이 10번정도 안떨어지면 학습 멈추게 하는 코드\n",
    "mc = ModelCheckpoint('aaaaa.h5', monitor='loss', mode='min', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "147/147 [==============================] - 2151s 15s/step - loss: 1.6370 - accuracy: 0.4021\n",
      "Epoch 2/15\n",
      "147/147 [==============================] - 2146s 15s/step - loss: 1.5097 - accuracy: 0.4524\n",
      "Epoch 3/15\n",
      "147/147 [==============================] - 2136s 15s/step - loss: 1.4912 - accuracy: 0.4591\n",
      "Epoch 4/15\n",
      "147/147 [==============================] - 2131s 14s/step - loss: 1.4739 - accuracy: 0.4667\n",
      "Epoch 5/15\n",
      "147/147 [==============================] - 2160s 15s/step - loss: 1.4695 - accuracy: 0.4705\n",
      "Epoch 6/15\n",
      "147/147 [==============================] - 2134s 15s/step - loss: 1.4570 - accuracy: 0.4730\n",
      "Epoch 7/15\n",
      "147/147 [==============================] - 2132s 15s/step - loss: 1.4402 - accuracy: 0.4778\n",
      "Epoch 8/15\n",
      "147/147 [==============================] - 2136s 15s/step - loss: 1.4266 - accuracy: 0.4857\n",
      "Epoch 9/15\n",
      "147/147 [==============================] - 2132s 15s/step - loss: 1.4117 - accuracy: 0.4933\n",
      "Epoch 10/15\n",
      "147/147 [==============================] - 2132s 15s/step - loss: 1.3939 - accuracy: 0.5026\n",
      "Epoch 11/15\n",
      "147/147 [==============================] - 2128s 14s/step - loss: 1.3782 - accuracy: 0.5014\n",
      "Epoch 12/15\n",
      "147/147 [==============================] - 2145s 15s/step - loss: 1.3634 - accuracy: 0.5122\n",
      "Epoch 13/15\n",
      "147/147 [==============================] - 2199s 15s/step - loss: 1.3462 - accuracy: 0.5151\n",
      "Epoch 14/15\n",
      "147/147 [==============================] - 2216s 15s/step - loss: 1.3312 - accuracy: 0.5244\n",
      "Epoch 15/15\n",
      "147/147 [==============================] - 2217s 15s/step - loss: 1.3128 - accuracy: 0.5251\n"
     ]
    }
   ],
   "source": [
    "training_epochs = 15\n",
    "num_batch_size = 64\n",
    "\n",
    "learning_rate = 0.001\n",
    "opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(x_train_input, y_train, batch_size=num_batch_size, epochs=training_epochs, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 저장한 파일 경로 설정\n",
    "model_path = 'E:/Competition/ETRI Competition/Analysis/final_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x24f8b247ee0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 로드\n",
    "audio_model = load_model(model_path)\n",
    "audio_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:/Competition/ETRI Competition/RAW DATA/KEMDy19/wav/test/Session03/Sess03_impro01/Sess03_impro01_F001.wav',\n",
       " 'E:/Competition/ETRI Competition/RAW DATA/KEMDy19/wav/test/Session03/Sess03_impro01/Sess03_impro01_F002.wav',\n",
       " 'E:/Competition/ETRI Competition/RAW DATA/KEMDy19/wav/test/Session03/Sess03_impro01/Sess03_impro01_F003.wav']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_t = 'E:/Competition/ETRI Competition/RAW DATA/KEMDy19/wav/test'    #데이터폴더 경로 지정해주기 \n",
    "parent_folders_t = os.listdir(path_t)                     #폴더 불러오기\n",
    "path_li_t = []\n",
    "total_sum_t = 0\n",
    "for parent_folder_t in parent_folders_t:\n",
    "    child_folders_t = []\n",
    "    child_folders_t.append((np.array(os.listdir(path_t+\"/\"+parent_folder_t)).flatten().tolist())) # wav에 있는 폴더 다 불러오기\n",
    "    temp_folders_t = (np.array(child_folders_t)).flatten().tolist()\n",
    "    for folder_t in temp_folders_t:\n",
    "        files_t = os.listdir(path_t+\"/\"+parent_folder_t+\"/\"+folder_t) #sessio01폴더 불러오기\n",
    "        for file_t in files_t:\n",
    "            if (path_t+\"/\"+parent_folder_t+'/'+folder_t+'/'+file_t).endswith('.wav') == True: # session01_impro01안에있는 txt 파일만 순서대로 path_li로 보내기\n",
    "                path_li_t.append(path_t+\"/\"+parent_folder_t+\"/\"+folder_t+\"/\"+file_t)\n",
    "\n",
    "path_li_t[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2095"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(path_li_t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14-45초 음성 파일을 10초자리로 데이터 shape 맞춰주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14초이상 되는 음성 파일들을 가져옴\n",
    "audio_files_t = []\n",
    "for filename_t in path_li_t: # 음성 파일이 저장된 폴더 경로\n",
    "    y_t, sr_t = librosa.load(filename_t, sr=16000)\n",
    "    duration_t = librosa.get_duration(y=y_t, sr=sr_t)\n",
    "    if duration_t < 14:\n",
    "        continue\n",
    "    audio_files_t.append(filename_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(audio_files_t)  #14초이상 124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14초~45초 되는 음성 파일들을 저장할 폴더 경로\n",
    "slid_test = 'E:/Competition/ETRI Competition/RAW DATA/KEMDy19/wav/test/slid_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_duration = 10\n",
    "\n",
    "for file_path_t in audio_files_t:\n",
    "    filename_t = os.path.basename(file_path_t)\n",
    "    y_t, sr_t = librosa.load(file_path_t, sr=16000, offset=0)\n",
    "    num_segments = int(np.ceil(len(y) / (segment_duration * sr)))\n",
    "    for i in range(num_segments):\n",
    "        start = i * segment_duration\n",
    "        end = (i + 1) * segment_duration\n",
    "        y_segment = y[int(start * sr):int(end * sr)]\n",
    "        output_file_t = os.path.join(slid_test, f'{filename_t}.wav')\n",
    "        sf.write(output_file_t, y_segment, sr_t, subtype='PCM_16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_delete_t in audio_files_t:  #14초이상 45초 미만 음성파일 삭제\n",
    "    os.remove(file_delete_t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\librosa\\feature\\spectral.py:2157: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-672.8785   , -671.7775   , -673.7934   , ...,    0.       ,\n",
       "           0.       ,    0.       ],\n",
       "       [  66.01541  ,   67.96032  ,   65.612915 , ...,    0.       ,\n",
       "           0.       ,    0.       ],\n",
       "       [  11.4209   ,   29.732376 ,   25.676243 , ...,    0.       ,\n",
       "           0.       ,    0.       ],\n",
       "       ...,\n",
       "       [   1.1737795,    1.9922352,    1.7162523, ...,    0.       ,\n",
       "           0.       ,    0.       ],\n",
       "       [  -2.7105546,   -3.4214401,   -3.694456 , ...,    0.       ,\n",
       "           0.       ,    0.       ],\n",
       "       [  -0.7262459,   -3.2338257,   -3.091505 , ...,    0.       ,\n",
       "           0.       ,    0.       ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_pad_len_t = 3300\n",
    "hop_length_t = 160  # 전체 frame 수 (hop_length의 길이만큼 옆으로 가면서 데이터를 읽는 옵션, 10ms를 기본으로 하고 있어 16000Hz인 음성에서는 160에 해당)\n",
    "n_fft_t = 400       # frame 하나당 sample 수(일반적으로 자연어 처리에서는 음성을 25m의 크기를 기본으로 하고 있으며 16000Hz인 음성에서는 400에 해당하는 값) \n",
    "\n",
    "out_t = []\n",
    "for file_t in path_li_t:\n",
    "    data_t, sr_t = librosa.load(file_t)  # librosa로 음성 데이터 불러오기\n",
    "    mfccs_t = librosa.feature.mfcc(y=data_t, sr=sr_t, n_fft=n_fft_t, hop_length=hop_length_t, n_mfcc=128)  #mfcc로 음성을 array형태로 나타냄\n",
    "    pad_width_t = max_pad_len_t - mfccs_t.shape[1]\n",
    "    if pad_width_t < 0:\n",
    "        mfcc_sh_t = mfccs_t[:, :max_pad_len_t]\n",
    "    else:\n",
    "        mfcc_sh_t = np.pad(mfccs_t, pad_width=((0, 0), (0, pad_width_t)), mode='constant')\n",
    "    out_t.append(mfcc_sh_t)\n",
    "out_t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2095"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Segment ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sess03_impro01_F001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sess03_impro01_F002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sess03_impro01_F003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sess03_impro01_F004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sess03_impro01_F006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>Sess17_script04_M012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>Sess17_script04_M014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2092</th>\n",
       "      <td>Sess17_script05_M023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>Sess17_script06_M013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>Sess17_script06_M023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2095 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Segment ID\n",
       "0      Sess03_impro01_F001\n",
       "1      Sess03_impro01_F002\n",
       "2      Sess03_impro01_F003\n",
       "3      Sess03_impro01_F004\n",
       "4      Sess03_impro01_F006\n",
       "...                    ...\n",
       "2090  Sess17_script04_M012\n",
       "2091  Sess17_script04_M014\n",
       "2092  Sess17_script05_M023\n",
       "2093  Sess17_script06_M013\n",
       "2094  Sess17_script06_M023\n",
       "\n",
       "[2095 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seesid_li_t = []\n",
    "label_li_t = []\n",
    "for path_t in path_li_t:\n",
    "    seesid_t = (path_t.split('/')[-1].split('.')[0])\n",
    "    seesid_li_t.append(seesid_t)\n",
    "seesid_df_t = pd.DataFrame(seesid_li_t)\n",
    "seesid_df_t.columns = ['Segment ID']\n",
    "seesid_df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path_t = 'E:/Competition/ETRI Competition/Analysis/감정 레이블/test 감정_보이스'  # 감정레이블 경로설정\n",
    "label_filename_t = os.listdir(label_path_t)                                  # 경로 설정한 폴더 열기\n",
    "label_li_t = [label_file_t for label_file_t in label_filename_t if label_file_t.endswith('.csv')]  # .csv 파일만 블러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2095\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Numb</th>\n",
       "      <th>Segment ID</th>\n",
       "      <th>Total Evaluation Emotion</th>\n",
       "      <th>Total Evaluation Valence</th>\n",
       "      <th>Total Evaluation Arousal</th>\n",
       "      <th>Eval01F Emotion</th>\n",
       "      <th>Eval01F Valence</th>\n",
       "      <th>Eval01F Arousal</th>\n",
       "      <th>Eval02F Emotion</th>\n",
       "      <th>Eval02F Valence</th>\n",
       "      <th>...</th>\n",
       "      <th>Eval17M Arousal</th>\n",
       "      <th>Eval18F Emotion</th>\n",
       "      <th>Eval18F Valence</th>\n",
       "      <th>Eval18F Arousal</th>\n",
       "      <th>Eval19M Emotion</th>\n",
       "      <th>Eval19M Valence</th>\n",
       "      <th>Eval19M Arousal</th>\n",
       "      <th>Eval20F Emotion</th>\n",
       "      <th>Eval20F Valence</th>\n",
       "      <th>Eval20F Arousal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Sess03_script01_M001</td>\n",
       "      <td>surprise</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>surprise</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>surprise</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sess03_script01_F001</td>\n",
       "      <td>fear</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>fear</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>fear</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Sess03_script01_M002</td>\n",
       "      <td>angry</td>\n",
       "      <td>1.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>angry</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>angry</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Sess03_script01_M003</td>\n",
       "      <td>angry</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>angry</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>sad</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Sess03_script01_F002</td>\n",
       "      <td>fear</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>fear</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>surprise</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Numb            Segment ID Total Evaluation Emotion  \\\n",
       "0     1  Sess03_script01_M001                 surprise   \n",
       "1     2  Sess03_script01_F001                     fear   \n",
       "2     3  Sess03_script01_M002                    angry   \n",
       "3     4  Sess03_script01_M003                    angry   \n",
       "4     5  Sess03_script01_F002                     fear   \n",
       "\n",
       "   Total Evaluation Valence  Total Evaluation Arousal Eval01F Emotion  \\\n",
       "0                       1.8                       3.5        surprise   \n",
       "1                       1.7                       3.7            fear   \n",
       "2                       1.4                       4.0           angry   \n",
       "3                       1.5                       3.9           angry   \n",
       "4                       1.9                       3.6            fear   \n",
       "\n",
       "   Eval01F Valence  Eval01F Arousal Eval02F Emotion  Eval02F Valence  ...  \\\n",
       "0              3.0              4.0        surprise              2.0  ...   \n",
       "1              1.0              4.0            fear              2.0  ...   \n",
       "2              1.0              5.0           angry              2.0  ...   \n",
       "3              1.0              4.0             sad              2.0  ...   \n",
       "4              1.0              4.0        surprise              2.0  ...   \n",
       "\n",
       "   Eval17M Arousal Eval18F Emotion  Eval18F Valence  Eval18F Arousal  \\\n",
       "0              NaN             NaN              NaN              NaN   \n",
       "1              NaN             NaN              NaN              NaN   \n",
       "2              NaN             NaN              NaN              NaN   \n",
       "3              NaN             NaN              NaN              NaN   \n",
       "4              NaN             NaN              NaN              NaN   \n",
       "\n",
       "  Eval19M Emotion  Eval19M Valence  Eval19M Arousal Eval20F Emotion  \\\n",
       "0             NaN              NaN              NaN             NaN   \n",
       "1             NaN              NaN              NaN             NaN   \n",
       "2             NaN              NaN              NaN             NaN   \n",
       "3             NaN              NaN              NaN             NaN   \n",
       "4             NaN              NaN              NaN             NaN   \n",
       "\n",
       "   Eval20F Valence  Eval20F Arousal  \n",
       "0              NaN              NaN  \n",
       "1              NaN              NaN  \n",
       "2              NaN              NaN  \n",
       "3              NaN              NaN  \n",
       "4              NaN              NaN  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 감정라벨\n",
    "total_label_df_t = pd.DataFrame()  \n",
    "for filename_t in label_li_t:\n",
    "    temp_label_df_t = pd.read_csv(label_path_t+'/'+filename_t)  # 감정레이블 파일 내용 읽어드리기\n",
    "    total_label_df_t = pd.concat([total_label_df_t, temp_label_df_t], axis=0) \n",
    "\n",
    "total_label_df_t = total_label_df_t.reset_index(drop=True) \n",
    "print(len(total_label_df_t))\n",
    "\n",
    "total_label_df_t[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2095\n",
      "0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#wav와 label을 segment id기준으로 다른게 있는지 확인\n",
    "\n",
    "label_value_li_t = []\n",
    "non_li_t = []\n",
    "non_seg_li_t = []\n",
    "joungbok_li_t = []\n",
    "for i_t in range(len(seesid_df_t)):\n",
    "   check_t = 0\n",
    "   for k_t in range(len(total_label_df_t)):\n",
    "       if check_t == 0:\n",
    "           if seesid_df_t['Segment ID'][i_t] == total_label_df_t['Segment ID'][k_t]:\n",
    "               label_value_li_t.append(total_label_df_t['Total Evaluation Emotion'][k_t])\n",
    "               check_t = 1\n",
    "       elif check_t == 1:\n",
    "           if seesid_df_t['Segment ID'][i_t] == total_label_df_t['Segment ID'][k_t]:\n",
    "               joungbok_li_t.append(seesid_df_t['Segment ID'][i_t])\n",
    "               check_t = 1\n",
    "print(len(label_value_li_t))\n",
    "print(len(joungbok_li_t))\n",
    "print(joungbok_li_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 데이터프레임에서 공통으로 포함된 Segment ID를 찾습니다.\n",
    "common_ids = seesid_df_t['Segment ID'].isin(total_label_df_t['Segment ID'])\n",
    "\n",
    "# 두 데이터프레임에서 공통으로 포함되지 않은 Segment ID를 찾습니다.\n",
    "different_ids = ~common_ids\n",
    "\n",
    "# different_ids를 사용하여 seesid_df_t에서 공통되지 않은 Segment ID를 찾습니다.\n",
    "unique_seesid = seesid_df_t.loc[different_ids, 'Segment ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "629    Sess04_impro03_F025\n",
       "Name: Segment ID, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_seesid # 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2095, 128, 3300)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = np.array(out_t)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2095,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test1 = np.array(label_value_li_t)\n",
    "y_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "(2095, 7)\n"
     ]
    }
   ],
   "source": [
    "le1 = LabelEncoder()\n",
    "arr_float = to_categorical(le1.fit_transform(y_test1))\n",
    "y_test = arr_float.astype(np.int64)\n",
    "print(y_test.dtype)\n",
    "print(arr_float.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예측모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 106s 2s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = audio_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label_li = []\n",
    "pred_label_li = []\n",
    "for i in range(len(y_test)):\n",
    "    real_label_li.append(np.argmax(y_test[i]))\n",
    "    pred_label_li.append(np.argmax(predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prediction\n",
       "0           4\n",
       "1           5\n",
       "2           4\n",
       "3           4\n",
       "4           4"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측값을 데이터프레임으로 변환\n",
    "#df = pd.DataFrame({'Prediction': pred_label_li})\n",
    "#df.to_csv('voice_predictions.csv', index=False)\n",
    "\n",
    "#print(df[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4505966587112172\n"
     ]
    }
   ],
   "source": [
    "counter = 0 \n",
    "total = 0 \n",
    "for k in range(len(real_label_li)):\n",
    "    total += 1\n",
    "    if real_label_li[k] == pred_label_li[k]:\n",
    "        counter += 1\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print(\"Accuracy: \", counter / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = tfa.metrics.F1Score(num_classes=7,average='macro', threshold=None, name='f1_score', dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "f1_score:  0.29646128\n"
     ]
    }
   ],
   "source": [
    "metric.update_state(y_test, predictions)\n",
    "result = metric.result()\n",
    "#result.numpy()\n",
    "print(\"f1_score: \", result.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
